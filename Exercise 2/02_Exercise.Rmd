---
title: "Exercise 2"
author: "Mads Adrian Simonsen, William Scott Grundeland Olsen"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document: default
  github_document: default
  html_document:
    df_print: paged
subtitle: TMA4300 Computer Intensive Statistical Models
---

```{r setup, include=FALSE}
library(rmarkdown)  # Dynamic Documents for R
library(knitr)  # A General-Purpose Package for Dynamic Report Generation in R
knitr::opts_chunk$set(echo = TRUE, tidy = FALSE, message = FALSE, warning = FALSE,
                      strip.white = TRUE, prompt = FALSE, cache = TRUE,
                      size = "scriptsize", fig.width = 6, fig.height = 4)
```

\newcommand{\E}{\operatorname E}
\newcommand{\Var}{\operatorname{Var}}
\newcommand{\Cov}{\operatorname{Cov}}
\newcommand{\Corr}{\operatorname{Corr}}
\newcommand{\Exp}{\operatorname{Exponential}}
\newcommand{\Uniform}{\operatorname{Uniform}}
\newcommand{\Betadist}{\operatorname{Beta}}
\newcommand{\Gammadist}{\operatorname{Gamma}}
\newcommand{\Normal}{\operatorname{Normal}}
\newcommand{\SD}{\operatorname{SD}}
\newcommand{\RSS}{\mathrm{RSS}}
\newcommand{\MSE}{\mathrm{MSE}}
\newcommand{\T}{\mathsf T}
\newcommand{\tr}{\operatorname{tr}}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\Bias}{\operatorname{Bias}}
\newcommand{\diag}{\operatorname{diag}}
\newcommand{\argmin}{\operatorname*{arg\,min}}
\newcommand{\argmax}{\operatorname*{arg\,max}}
\newcommand{\bfy}{\mathbf{y}}
\newcommand{\bff}{\mathbf{f}}
\newcommand{\bfzero}{\mathbf{0}}
\newcommand{\bfeta}{\boldsymbol{\eta}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\e}{\mathrm{e}}


```{r libraries, eval = TRUE, echo = FALSE}
library(tidyverse)  # Collection of R packages designed for data science

library(INLA)       # Full Bayesian Analysis of Latent Gaussian Models using Integrated
                    # Nested Laplace Approximations
```

# Problem A: The coal-mining disaster data

## Subproblem 1.


[//]: # ----------------------------------------------------------------------------------------------------------------

## Subproblem 2.


[//]: # ----------------------------------------------------------------------------------------------------------------

## Subproblem 3.


[//]: # ----------------------------------------------------------------------------------------------------------------

## Subproblem 4.


[//]: # ----------------------------------------------------------------------------------------------------------------

## Subproblem 5.


[//]: # ----------------------------------------------------------------------------------------------------------------

## Subproblem 6.


[//]: # ----------------------------------------------------------------------------------------------------------------

## Subproblem 7.

### Subsubproblem (a)

### Subsubproblem (b)


[//]: # ----------------------------------------------------------------------------------------------------------------

## Subproblem 8.


[//]: # ----------------------------------------------------------------------------------------------------------------
[//]: # ----------------------------------------------------------------------------------------------------------------


# Problem B: INLA for Gaussian Data
We plot the dataset in the following code block, and the result is shown in Figure \ref{fig:TimesSeriesOfGaussianData}.
```{r Plot Gaussian data, fig.width = 4, fig.height = 2, fig.cap = "\\label{fig:TimesSeriesOfGaussianData}The dataset \\texttt{Gaussiandata.txt} plotted."}
# Importing the data and making relevant variables
path <- "https://www.math.ntnu.no/emner/TMA4300/2020v/Exercise/exercise2/Gaussiandata.txt"
gauss_data <- read.delim(path, header = FALSE)  # There is no header in the dataset
y <- gauss_data[, 1]  # For plotting
TT <- length(y)       # End point of the data
t <- seq(1, TT, 1)    # A sequence from 1 to 20 for plotting

# Plotting
ggplot(mapping = aes(t, y)) +
  geom_point() +
  ggtitle("Plot of the Gaussian data") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

[//]: # ----------------------------------------------------------------------------------------------------------------

## Subproblem 1.
We assume that, given $\bfeta = \begin{bmatrix} \eta_1 & \cdots & \eta_T \end{bmatrix}^\top$, the observations $y_t$ of the time series are independent and Gaussian distributed with mean $\eta_t$ and known unit variance. Furthermore, the linear predictor $\eta_t$ is linked to a smooth effect of time $t$ as $\eta_t = f_t$, where the vector $\bff = \begin{bmatrix} f_1 & \cdots & f_T \end{bmatrix}^\top$ is the latent field. Choosing a second order random walk model as a prior distribution for $\bff$ we get that $\bff \mid \theta \sim \Normal(\bfzero, Q(\theta)^{-1})$, for some precision matrix $Q(\theta)$. The model is completed by assigning the prior $\theta \sim \Gammadist(1, 1)$.

The class of latent Gaussian models can be represented by a hierarchical structure containing three stages. In the case of this model it can be written in the stages
$$
  \bfy \mid \bff \sim \prod_{t=1}^T \pi(y_t \mid \eta_t),
  \quad
  \bff \mid \theta \sim \Normal(\bfzero, Q(\theta)^{-1})
  \quad \text{and} \quad
  \theta \sim \Gammadist(1, 1),
$$
where $Q$ is the precision matrix, and $y_t \mid \eta_t \sim \Normal(\eta_t, 1)$, for $t = 1, \dots, T$. Thus, because the model here can be written in the above form, it is a latent Gaussian model.

INLA is applicable for use in latent Gaussian models under some constraints. Firstly, the hyperparameter vector cannot be to large, and in this model it is just a scalar, so this is satisfied. Secondly, the precision matrix needs to be sparse, which is the case for a second order random walk model. We look further at
$$
  \pi(\bff \mid \theta) \propto \theta^{(T-2)/2} \exp\left[ -\frac{\theta}{2} \sum_{t=3}^T (f_t - 2 f_{t-1} + f_{t-2})^2 \right] = \theta^{(T-2)/2} \exp\left[ -\frac{1}{2} \bff^\top Q(\theta) \bff \right],
$$
and want to determine $Q(\theta)$, so we look more at the exponent. We get that
$$
  \theta \sum_{t=3}^T (f_t - 2 f_{t-1} + f_{t-2})^2 = \theta \sum_{t=3}^T (f_t^2 + 4 f_{t-1}^2 + f_{t-2}^2 - 4 f_t f_{t-1} + 2 f_t f_{t-2} - 4 f_{t-1} f_{t-2}) = \bff^\top Q(\theta) \bff,
$$
with the precision matrix
$$
  Q(\theta) = \theta
  \begin{bmatrix}
    1 & -2 & 1 &  &  &  &  &  & 
     \\
    -2 & 5 & -4 & 1 &  &  &  &  & 
     \\
    1 & -4 & 6 & -4 & 1 &  &  &  & 
     \\
     & 1 & -4 & 6 & -4 & 1 &  &  & 
     \\
     &  & \ddots & \ddots & \ddots & \ddots & \ddots &  & 
     \\
     &  &  & 1 & -4 & 6 & -4 & 1 & 
     \\
     &  &  &  & 1 & -4 & 6 & -4 & 1
     \\
     &  &  &  &  & 1 & -4 & 5 & -2
     \\
     &  &  &  &  &  & 1 & -2 & 1
     \\
  \end{bmatrix},
$$
where the elements not filled in are zero, that is, a sparse matrix. There is also a multiplication, such that all elements gets a factor $\theta$. We also write $Q = Q(\theta)/\theta$.

All the criteria to be able to use INLA is thus satisfied, and it can be applied to the model.


[//]: # ----------------------------------------------------------------------------------------------------------------

## Subproblem 2.
We now want to define and implement a block Gibbs sampling algorithm for $f(\bfeta, \theta \mid \bfy)$ by proposing a new value for $\theta$ from the full conditional $\pi(\theta \mid \bfeta, \bfy)$, and proposing a new value for $\bfeta$ from the full conditional $\pi(\bfeta \mid \theta, \bfy)$. Noting that $\bff = \bfeta$, we firstly have that
\begin{align*}
  f(\bfeta, \theta \mid \bfy) &\propto \pi(\bfy \mid \bfeta, \theta) \pi(\bfeta \mid \theta) \pi(\theta)
  \\
  &\propto \left\{ \prod_{t=1}^T \exp\left[ -\frac{1}{2} (y_t - \eta_t)^2 \right] \right\} \left\{ \theta^{(T-2)/2} \exp\left[ -\frac{\theta}{2} \sum_{t=3}^T (\eta_t - 2 \eta_{t-1} + \eta_{t-2})^2 \right] \right\} \exp(-\theta)
  \\
  &= \theta^{(T-2)/2} \exp\left[ -\theta - \frac{\theta}{2} \sum_{t=3}^T (\eta_t - 2 \eta_{t-1} + \eta_{t-2})^2 - \frac{1}{2} \sum_{t=1}^T (y_t - \eta_t)^2 \right],
\end{align*}
and we can from this find the full conditionals. This gives us
$$
  \pi(\theta \mid \bfeta, \bfy) \propto \theta^{(T-2)/2} \exp\left[ -\theta - \frac{\theta}{2} \sum_{t=3}^T (\eta_t - 2 \eta_{t-1} + \eta_{t-2})^2 \right] = \theta^{(T-2)/2} \exp\left[ -\theta - \frac{\theta}{2} \bfeta^\top Q \bfeta \right],
$$
and we note that
$$
  \theta \mid \bfeta, \bfy \sim \Gammadist\left( \frac{T}{2}, 1 + \frac{1}{2} \bfeta^\top Q \bfeta \right),
$$
where we use the shape and rate parameter. We can also find
\begin{align*}
  \pi(\bfeta \mid \theta, \bfy) &\propto \exp\left[ -\frac{\theta}{2} \sum_{t=3}^T (\eta_t - 2 \eta_{t-1} + \eta_{t-2})^2 - \frac{1}{2} \sum_{t=1}^T (y_t - \eta_t)^2 \right]
  \\
  &= \exp\left[ -\frac{1}{2} \bfeta^\top Q(\theta) \bfeta - \frac{1}{2} (\bfy - \bfeta)^\top (\bfy - \bfeta) \right]
  \\
  &= \exp\left[ -\frac{1}{2} (\bfeta^\top Q(\theta) \bfeta + \bfeta^\top \bfeta + \bfy^\top \bfy) + \bfy^\top \bfeta \right]
  \\
  &\propto \exp\left[ \bfy^\top \bfeta - \frac{1}{2} \bfeta^\top (Q(\theta) + I) \bfeta \right],
\end{align*}
where $I \in \RR^{T \times T}$ is the identity matrix. It is then clear that
$$
  \bfeta \mid \theta, \bfy \sim \Normal((Q(\theta) + I)^{-1} \bfy, (Q(\theta) + I)^{-1}),
$$
because we recognize the canonical form of the Gaussian.

We can then create the matrix $Q$ as `Q(TT, theta)` in `R`, done in the following code block. Note that we then have that for the matrix $Q$ that `theta = 1`. Here we use that $Q(\theta) = \theta M^\top M$ for the matrix $M$ coming from the fact that we have $\sum_{t=3}^T (f_t - 2f_{t-1} + f_{t-2})^2$.
```{r Define Q matrix}
Q <- function(TT, theta) {
  M <- matrix(0, nrow = TT, ncol = TT)  # Matrix of zeros of size TT times TT
  for (i in 3:TT) { # Create two matrices corresponding to RW2 to be multiplied
    M[i, c(i-2, i-1, i)] <- c(1, -2, 1)
  }
  return(theta * t(M) %*% M)  # Q(theta)
}
```


[//]: # ----------------------------------------------------------------------------------------------------------------

## Subproblem 3.



[//]: # ----------------------------------------------------------------------------------------------------------------

## Subproblem 4.



[//]: # ----------------------------------------------------------------------------------------------------------------

## Subproblem 5.



[//]: # ----------------------------------------------------------------------------------------------------------------
[//]: # ----------------------------------------------------------------------------------------------------------------